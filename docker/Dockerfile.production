# PRODUCTION DOCKERFILE - All Critical Issues Fixed
# Target: Wan2.2-Animate-14B face-swapper for Runpod serverless
# Build time: ~45-60 minutes (includes 14GB+ model download)
# Final size: ~67GB

FROM pytorch/pytorch:2.1.0-cuda11.8-cudnn8-devel

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1

# Install system dependencies with ALL required libraries
RUN apt-get update && \
    apt-get install -y \
        # Build tools (for insightface compilation)
        build-essential \
        cmake \
        pkg-config \
        # Git and version control
        git \
        # Video processing
        ffmpeg \
        # OpenCV dependencies (COMPLETE SET)
        libgl1-mesa-glx \
        libglib2.0-0 \
        libsm6 \
        libxext6 \
        libxrender-dev \
        libgomp1 \
        libgtk2.0-dev \
        # Python development headers
        python3-dev && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app
RUN mkdir -p /models /tmp/processing

# Install packages in CORRECT ORDER (dependencies first)
# Step 1: Core packages
RUN pip install --no-cache-dir \
    runpod>=1.3.0 \
    boto3 \
    requests \
    numpy \
    PyYAML \
    tqdm

# Step 2: Computer vision packages (need build tools)
RUN pip install --no-cache-dir \
    opencv-python \
    opencv-contrib-python \
    Pillow

# Step 3: Deep learning packages
RUN pip install --no-cache-dir \
    huggingface-hub[cli] \
    einops \
    transformers \
    diffusers \
    accelerate \
    omegaconf \
    safetensors

# Step 4: Face detection (problematic packages installed separately with error handling)
RUN pip install --no-cache-dir retinaface-pytorch || echo "retinaface-pytorch optional"
RUN pip install --no-cache-dir insightface || echo "insightface optional"

# Step 5: Video processing
RUN pip install --no-cache-dir \
    ffmpeg-python \
    moviepy

# Step 6: Additional utilities from requirements.txt
RUN pip install --no-cache-dir \
    python-dotenv \
    python-json-logger

# Clone Wan2.2 repository
RUN git clone https://github.com/Wan-Video/Wan2.2.git /app/Wan2.2

# Download model weights (14GB+, may take 15-30 minutes)
# FIXED: Consistent path naming
RUN huggingface-cli download Wan-AI/Wan2.2-Animate-14B --local-dir /models/Wan2.2-Animate-14B

# Create symlink for model path consistency
RUN ln -s /models/Wan2.2-Animate-14B /models/wan2.2-animate

# Copy application files
WORKDIR /app
COPY config.yaml handler.py process.py utils.py ./

# Environment variables
# FIXED: Model path matches download location
ENV MODEL_PATH=/models/Wan2.2-Animate-14B
# FIXED: Add Wan2.2 to Python path for imports
ENV PYTHONPATH=/app/Wan2.2:$PYTHONPATH
ENV CUDA_VISIBLE_DEVICES=0

# Verify critical imports work (fails build if broken)
RUN python3 -c "import torch; import cv2; print('Core imports: OK')" && \
    python3 -c "import sys; sys.path.insert(0, '/app/Wan2.2'); print('Wan2.2 path: OK')"

# Start handler
CMD ["python", "handler.py"]
