# Simpler approach - use official PyTorch image with CUDA pre-installed
FROM pytorch/pytorch:2.1.0-cuda11.8-cudnn8-runtime

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1

# Install only essential system packages
RUN apt-get update && \
    apt-get install -y git ffmpeg && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app
RUN mkdir -p /models /tmp/processing

# Install Python packages (PyTorch already installed in base image)
RUN pip install --no-cache-dir \
    runpod>=1.3.0 \
    boto3 \
    requests \
    opencv-python \
    Pillow \
    retinaface-pytorch \
    insightface \
    ffmpeg-python \
    moviepy \
    numpy \
    PyYAML \
    tqdm \
    huggingface-hub[cli] \
    einops \
    transformers \
    diffusers \
    accelerate \
    omegaconf \
    safetensors

# Clone and setup Wan2.2
RUN git clone https://github.com/Wan-Video/Wan2.2.git /app/Wan2.2

# Download model
RUN huggingface-cli download Wan-AI/Wan2.2-Animate-14B --local-dir /models/Wan2.2-Animate-14B

# Copy handler
WORKDIR /app
COPY config.yaml handler.py process.py utils.py ./

ENV MODEL_PATH=/models/wan2.2-animate
ENV CUDA_VISIBLE_DEVICES=0

CMD ["python", "handler.py"]
