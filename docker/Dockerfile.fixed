# FINAL WORKING DOCKERFILE - Using devel image with build tools
FROM pytorch/pytorch:2.1.0-cuda11.8-cudnn8-devel

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1

# Install system dependencies (git, ffmpeg, and BUILD TOOLS for opencv/insightface)
RUN apt-get update && \
    apt-get install -y \
        git \
        ffmpeg \
        libglib2.0-0 \
        libsm6 \
        libxext6 \
        libxrender-dev \
        libgomp1 && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app
RUN mkdir -p /models /tmp/processing

# Install packages in CORRECT ORDER (dependencies first)
# Step 1: Core packages
RUN pip install --no-cache-dir \
    runpod>=1.3.0 \
    boto3 \
    requests \
    numpy \
    PyYAML \
    tqdm

# Step 2: Computer vision packages (need build tools)
RUN pip install --no-cache-dir \
    opencv-python \
    Pillow

# Step 3: Deep learning packages
RUN pip install --no-cache-dir \
    huggingface-hub[cli] \
    einops \
    transformers \
    diffusers \
    accelerate \
    omegaconf \
    safetensors

# Step 4: Face detection (problematic packages installed separately)
RUN pip install --no-cache-dir retinaface-pytorch || echo "retinaface-pytorch optional"
RUN pip install --no-cache-dir insightface || echo "insightface optional"

# Step 5: Video processing
RUN pip install --no-cache-dir \
    ffmpeg-python \
    moviepy

# Clone Wan2.2
RUN git clone https://github.com/Wan-Video/Wan2.2.git /app/Wan2.2

# Download model
RUN huggingface-cli download Wan-AI/Wan2.2-Animate-14B --local-dir /models/Wan2.2-Animate-14B

# Copy handler
WORKDIR /app
COPY config.yaml handler.py process.py utils.py ./

ENV MODEL_PATH=/models/wan2.2-animate
ENV CUDA_VISIBLE_DEVICES=0

CMD ["python", "handler.py"]
