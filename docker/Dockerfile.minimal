# MINIMAL DOCKERFILE - Fast iteration, download model at runtime
# Build time: ~15-20 minutes (no model bundling)
# Final size: ~15GB
# Use case: Development, testing, rapid iteration

FROM pytorch/pytorch:2.1.0-cuda11.8-cudnn8-devel

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV HF_HOME=/models/.cache

# Install system dependencies (minimal set)
RUN apt-get update && \
    apt-get install -y \
        build-essential \
        cmake \
        git \
        ffmpeg \
        libgl1-mesa-glx \
        libglib2.0-0 \
        libsm6 \
        libxext6 \
        libxrender-dev \
        libgomp1 && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app
RUN mkdir -p /models /tmp/processing

# Install Python packages (consolidated for speed)
RUN pip install --no-cache-dir \
    runpod>=1.3.0 \
    boto3 \
    requests \
    numpy \
    PyYAML \
    tqdm \
    opencv-python \
    Pillow \
    huggingface-hub[cli] \
    einops \
    transformers \
    diffusers \
    accelerate \
    omegaconf \
    safetensors \
    ffmpeg-python \
    moviepy \
    python-dotenv \
    python-json-logger

# Optional packages (don't fail build)
RUN pip install --no-cache-dir retinaface-pytorch insightface || true

# Clone Wan2.2
RUN git clone https://github.com/Wan-Video/Wan2.2.git /app/Wan2.2

# Copy application files
COPY config.yaml handler.py process.py utils.py ./

# Environment variables
ENV MODEL_PATH=/models/Wan2.2-Animate-14B
ENV PYTHONPATH=/app/Wan2.2:$PYTHONPATH
ENV CUDA_VISIBLE_DEVICES=0

# Create startup script that downloads model on first run
RUN cat > /app/download_model.sh << 'SCRIPT'
#!/bin/bash
if [ ! -d "/models/Wan2.2-Animate-14B" ]; then
    echo "Downloading model (first run only, ~14GB)..."
    huggingface-cli download Wan-AI/Wan2.2-Animate-14B --local-dir /models/Wan2.2-Animate-14B
    echo "Model download complete"
fi
SCRIPT

RUN chmod +x /app/download_model.sh

# Wrapper CMD that downloads model before starting handler
CMD ["/bin/bash", "-c", "/app/download_model.sh && python handler.py"]
